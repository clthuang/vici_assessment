# PRD: Claude-DA — Natural Language Data Analysis API

**Status**: Draft (reviewed x3, claims verified, simplified)
**Created**: 2026-02-07
**Author**: Brainstorm session

---

## 1. Problem Statement

Data analysis today requires knowing SQL, understanding schemas, and translating between business questions and technical queries. Non-technical stakeholders depend on analysts for every question. Existing AI solutions either require custom integrations per database or lack the agentic capability to autonomously explore data and generate insights.

**Core insight**: Claude Code already knows how to reason about data, write SQL, execute queries, and explain results. MCP servers already provide standardized database access. LiteLLM already provides an OpenAI-compatible gateway. Claude-DA connects these three pieces into a product.

## 2. Solution Overview

Claude-DA is a **LiteLLM custom provider** that exposes Claude Code's agentic data analysis capabilities through a standard OpenAI-compatible API. Point it at your databases (via MCP servers), and any OpenAI-compatible client becomes an AI data analyst.

```
Any OpenAI client ──► LiteLLM Proxy ──► Claude-DA Provider ──► Claude Code
(Open WebUI, Slack,    (standard          (custom provider      ├── MCP: postgres-server
 curl, custom app)      gateway)           with DA expertise)    ├── MCP: mysql-server
                                                                 └── MCP: sqlite-server
```

### Key Value Proposition

| For whom | Value |
|---|---|
| Internal team members | Ask data questions in plain English via any chat UI |
| Internal developers | Standard OpenAI API — no new SDK to learn |
| Team leads | Centralized, governed access to data with virtual keys |
| Assessment | Demonstrates systems integration, security thinking, and product design |

### Target Users & Scope Disclaimer

**Claude-DA is an internal-facing tool, not a commercial product.** It is designed for:
- Internal teams who trust the deployment environment
- Developers and analysts within an organization
- Demo and assessment purposes

It is **not** designed for:
- Public-facing production use
- Untrusted external users
- Environments requiring enterprise-grade security certification

The security model provides reasonable guardrails for internal use (read-only DB, disabled dangerous tools, tool allowlists) but has not been penetration-tested or hardened against adversarial users.

## 3. User Stories

1. **As an internal team member** using a chat UI, I ask "What were our top 10 customers by revenue last month?" and get a clear answer with trends and context — not raw SQL output.
2. **As a developer**, I call the standard OpenAI chat completions endpoint with a data question and get structured insights I can embed in a dashboard.
3. **As a team lead**, I want each team member to have an API key with usage tracking so I can monitor costs.
4. **As an admin**, I configure which databases are accessible and enforce read-only access so the AI cannot modify production data.
5. **As a user**, I ask a non-data question and get a conversational response — the agent answers briefly but may note its primary role is data analysis.

## 4. Architecture

### 4.1 Component Overview

```
┌─────────────────────────────────────────────────────────┐
│  Claude-DA System                                       │
│                                                         │
│  ┌─────────────┐  ┌──────────────┐  ┌───────────────┐  │
│  │  LiteLLM    │  │  Claude-DA   │  │  Claude Code  │  │
│  │  Proxy      │──│  Provider    │──│  (Agent SDK)  │  │
│  │  (gateway)  │  │  (custom     │  │               │  │
│  │             │  │   handler)   │  │  Tools:       │  │
│  │  Features:  │  │              │  │  └─ MCP DBs   │  │
│  │  - Auth     │  │  Features:   │  │    (only)     │  │
│  │  - Keys     │  │  - System    │  │               │  │
│  │  - Budgets  │  │    prompt    │  │  Disabled:    │  │
│  │  - Logging  │  │  - Schema    │  │  ├─ Bash      │  │
│  │  - Routing  │  │    injection │  │  ├─ Write     │  │
│  │             │  │  - Input     │  │  └─ Edit      │  │
│  │             │  │    validation│  │               │  │
│  │             │  │  - Audit log │  │               │  │
│  └─────────────┘  └──────────────┘  └───────────────┘  │
│                                                         │
│  ┌─────────────────────────────────────────────────────┐│
│  │  MCP Database Servers (external, pre-existing)      ││
│  │  ├── @modelcontextprotocol/server-postgres          ││
│  │  ├── @modelcontextprotocol/server-mysql             ││
│  │  └── @modelcontextprotocol/server-sqlite            ││
│  └─────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────┘
```

### 4.2 Request Flow

1. Client sends a chat completions request with a natural language question
2. LiteLLM Proxy authenticates (virtual API key), applies budget checks
3. Routes to Claude-DA custom provider
4. Provider validates input (length limit, basic sanity checks)
5. Provider constructs enhanced prompt:
   - Injects data analyst system prompt
   - Injects discovered database schemas
   - Injects safety rules (read-only, row limits)
   - Passes user question
6. Claude Code (via Agent SDK) processes autonomously:
   - Reasons about what data is needed
   - Writes and executes SQL queries via MCP database tools
   - Analyzes results
   - Formulates insight-driven response
7. Provider logs the session (question, queries executed, response) for audit
8. Provider formats response as OpenAI-compatible ChatCompletion
9. Streams (or returns) to client

### 4.3 MCP Integration

Instead of building database connectors, Claude-DA configures Claude Code with MCP database servers. This means:
- **Zero custom DB code** — MCP servers handle connection pooling, query execution, schema introspection
- **Any database MCP supports** — PostgreSQL, MySQL, SQLite today; anything the MCP ecosystem adds tomorrow
- **Standardized interface** — Claude Code already speaks MCP natively
- **Community maintained** — MCP servers are actively developed by the community

MCP servers are launched as stdio subprocesses by the Agent SDK (same pattern as Claude Desktop). Configuration via environment variables.

### 4.4 Feasibility Verification

All load-bearing technical assumptions have been verified against official documentation.

#### Agent SDK Capabilities [VERIFIED]

The Claude Agent SDK (Python, v0.1.30) supports all required capabilities. Verified against the [official Agent SDK reference](https://platform.claude.com/docs/en/agent-sdk/python):

| Requirement | Supported | SDK Parameter |
|---|---|---|
| Configure MCP servers programmatically | Yes | `mcp_servers` — accepts server config dict or path to `.mcp.json` |
| Launch MCP servers as stdio subprocesses | Yes | Stdio is the default transport type |
| Restrict which tools the agent can use | Yes | `allowed_tools`, `disallowed_tools` — supports wildcards |
| Async iteration over agent responses | Yes | Returns `AsyncIterator[Message]` |
| Cap agentic loop iterations | Yes | `max_turns` — integer, default unlimited |
| Cap spend per request | Yes | `max_budget_usd` — float, default unlimited |

**Known issue (resolved)**: `allowed_tools` was ignored in SDK versions 0.1.5–0.1.9 ([#361](https://github.com/anthropics/claude-agent-sdk-python/issues/361)). Fixed in later versions. Pin to `>=0.1.30`.

**Fallback plan**: If Agent SDK integration hits unexpected issues, the CLI subprocess approach (`claude -p --mcp-config mcp.json`) is a proven alternative.

#### LiteLLM Custom Provider [VERIFIED]

LiteLLM's `CustomLLM` base class provides the integration interface. Verified against the [CustomLLM documentation](https://docs.litellm.ai/docs/providers/custom_llm_server):

- Requires implementing 4 methods: sync/async x streaming/non-streaming
- The proxy always uses the async variants
- Receives full OpenAI-format conversation history (not just latest message)
- Custom providers are registered via config and referenced as `"provider-name/model-name"`
- Streaming uses a standard chunk format with text, finish status, and usage fields

Full method signatures and chunk format are documented in the reference link above.

#### Prior Art Lessons [cabinlab/litellm-claude-code]

Reviewed the existing cabinlab project that wraps Claude Code SDK as a LiteLLM provider:
- **Confirms the CustomLLM approach works end-to-end** — the pattern is proven
- **"Partial streaming"** means they stream the final text response but do not stream intermediate tool-call events. This is the same approach we've chosen (stream final insight only)
- **OAuth token management** was a significant part of their implementation. We can simplify by using API keys only (internal tool, no OAuth needed)
- Our approach differs by specializing for data analysis with MCP database access rather than being a generic Claude Code proxy

### 4.5 Security Model

#### Tool Access Boundaries

**Enabled tools** (MVP): MCP database tools only (query, list_tables, describe_table)

**Explicitly disabled tools**: Bash, Write, Edit, Glob, Grep. Bash is the most critical — it would allow the agent to bypass MCP read-only controls by running database CLI tools directly.

The Agent SDK enforces tool restrictions at the SDK level — the agent cannot override them.

#### Defense Layers (honest assessment)

| Layer | Type | Bypassable? |
|---|---|---|
| Read-only DB user | **Hard enforcement** — database rejects writes | No (if configured correctly) |
| Bash/Write/Edit disabled | **Hard enforcement** — agent cannot shell out or modify files | No (enforced by SDK) |
| Tool allowlist | **Hard enforcement** — agent only sees approved MCP tools | No (enforced by SDK) |
| Input length limit | **Hard enforcement** — rejects oversized inputs before processing | No (applied pre-LLM) |
| System prompt rules | Soft guardrail — instructs read-only behavior | Yes (LLM could ignore) |
| Query pattern check | Soft guardrail — rejects obvious destructive SQL | Yes (SQL obfuscation) |
| Prompt sanitization | Soft guardrail — heuristic detection of injection patterns | Yes (novel encodings, payload splitting) |

The hard enforcement layers (read-only DB user, disabled tools, tool allowlist) are the **real** security boundaries. Prompt sanitization and query validation are supplementary heuristics that catch accidental misuse but cannot guarantee prevention. This distinction is intentional — the tool is internal-facing and not hardened against adversarial attack.

#### Startup Validation

On startup, Claude-DA verifies database connections are genuinely read-only:
- Attempts a write operation (e.g., `CREATE TEMP TABLE _health_check ...`) and confirms it fails
- If the write succeeds, the system **refuses to start** with a clear error message
- If the database is unreachable, retries with backoff; aborts after timeout

### 4.6 Failure Modes & Error Handling

| Failure | Behavior | Client sees |
|---|---|---|
| MCP DB server unreachable | Agent SDK tool call fails | Error: "Database unavailable" |
| Query times out | MCP server returns timeout error | Error: "Query timed out" |
| Claude generates invalid SQL | Agent self-corrects or gives up | Transparent retry or "Could not query" |
| Agent SDK call hangs | LiteLLM proxy timeout fires | HTTP 504 Gateway Timeout |
| Agent enters retry loop | `max_turns` caps iterations | Agent stops, returns best-effort response |
| Anthropic API rate limited | Agent SDK propagates 429 | HTTP 429 with retry-after header |
| Input too long | Length limit rejects pre-LLM | HTTP 400 with explanation |

**Timeout strategy**: LiteLLM proxy (300s) > Agent SDK (240s) > MCP query (30s). Each layer times out before its parent for graceful error propagation.

### 4.7 Cost & Latency Expectations

Each request involves an agentic loop, so costs and latency are higher than a simple API call:

| Scenario | Est. latency | Est. cost (Sonnet) |
|---|---|---|
| Simple query ("total revenue last month") | 5–15s | ~$0.03 |
| Multi-step analysis ("MoM trends by segment") | 15–45s | ~$0.10 |
| Non-data chat ("what's the weather?") | 3–8s | ~$0.01 |

System prompt with schema injection adds ~1–2k tokens per request (for a demo-sized ~6 table schema). This is the baseline cost of every request, including non-data questions. The full-vision "contextual schema injection" feature would optimize this.

`max_turns` and `max_budget_usd` provide hard caps on runaway agentic loops.

### 4.8 Risks & Limitations

#### System Limitations

| Limitation | Impact | Mitigation |
|---|---|---|
| **Non-deterministic responses** | The same question may produce different SQL or insights on different runs. | Acceptable for exploratory analysis. Not suitable for compliance or financial reporting requiring exact reproducibility. |
| **No query verification** | No guarantee the SQL is correct or that insights accurately answer the question. Logical errors (correct SQL, wrong answer) are undetectable. | Users must validate critical insights independently. |
| **Schema staleness** | Schema injected at startup. Runtime schema changes are invisible until restart. | Acceptable for MVP. Full vision includes runtime refresh. |
| **Concurrency** | Each request spawns an independent Agent SDK session (no shared state), but concurrent requests contend for system resources (memory, API rate limits). Not tested under concurrent load. | MVP targets single-user / low-concurrency. |
| **Latency** | 5–45 second response times. Fundamentally slower than pre-written dashboards. | Claude-DA is for ad-hoc exploration, not real-time dashboards. Streaming mitigates perceived wait. |

#### Risks

| Risk | Likelihood | Severity | Mitigation |
|---|---|---|---|
| **Data exfiltration via crafted queries** | Medium | High | Read-only access prevents writes, but a prompt injection could craft queries to extract sensitive data. Internal-only deployment is the primary mitigation. |
| **Hallucinated insights** | Medium | Medium | Claude may present plausible analysis not supported by data. Users must treat insights as hypotheses, not facts. |
| **Agent SDK breaking changes** | Medium | Medium | SDK is v0.1.x. Pin version, monitor releases. |
| **MCP server reliability** | Low | High | Community-maintained; bugs could cause silent failures. Pin versions; integration tests catch regressions. |
| **Cost runaway** | Low | Medium | `max_turns` and `max_budget_usd` are hard caps. Default to conservative limits. |
| **Anthropic API outage** | Low | High | System is entirely dependent on Anthropic's API. No local fallback. |

#### Audit data sensitivity

Audit logs contain raw query results. If a user asks "show me all customer emails", the result set is persisted to the log. Audit logs should be treated with the same access controls as the database itself.

#### What This System Is NOT

- **Not a BI tool** — does not replace Metabase/Looker/Tableau. No charts, scheduled reports, or dashboards.
- **Not an ETL pipeline** — reads data only. Does not transform or load.
- **Not auditable for compliance** — audit trails capture queries and results, but non-deterministic responses make it unsuitable for regulated environments.
- **Not secure against adversarial users** — designed for trusted internal use only.

### 4.9 Auditability & Traceability

Every Claude-DA request is logged as a structured record so that any insight can be traced back to the exact queries and raw data that produced it.

#### Approach

A single structured log per request, written to a configurable output (stdout, file, or both). Each log entry contains:

| Field | Content | Purpose |
|---|---|---|
| **Session ID** | Unique request identifier | Correlate all artifacts for one request |
| **Timestamp** | When the request was made | Chronological ordering |
| **User question** | Original input | What was asked |
| **SQL queries executed** | Ordered list of every SQL the agent ran | Reproducibility — anyone can re-run the exact queries |
| **Query results summary** | Row counts and column names (not full result sets by default) | Verify what the agent saw without storing sensitive data in logs |
| **Final response** | The insight text returned to the client | What the user received |
| **Metadata** | Model, tokens, cost estimate, duration, tool call count | Operational auditing and cost attribution |

#### Key Properties

- **Session-correlated**: All fields for a request are in a single log entry, keyed by session ID. No need to correlate across files.
- **Reproducible**: Given the SQL queries, anyone can re-run them against the database and verify the data.
- **Configurable verbosity**: Default logs query summaries (row counts). Verbose mode logs full result sets for debugging. This controls the audit data sensitivity tradeoff.
- **No separate infrastructure**: Uses standard logging. No audit database, no file system artifacts, no MCP server needed for MVP.

#### Full Vision

Post-MVP: structured audit storage (append-only SQLite), an MCP server for searching past sessions (any MCP client becomes the audit browser), retention policies, and Langfuse integration.

## 5. Full Feature Vision (North Star)

The MVP proves the core value chain. The full vision extends it in four directions:

- **Multi-database support** — PostgreSQL, MySQL, and other MCP-supported databases. Architecture is already DB-agnostic; adding databases is configuration, not code.
- **Intelligence** — contextual schema injection (only relevant tables per question), conversation memory for follow-up questions, result caching, and suggested explorations.
- **Governance** — capability profiles per API key, prompt sanitization hardening, virtual key budget enforcement, and structured audit storage with retention policies.
- **Observability** — action transparency (surface executed SQL in response metadata), Langfuse integration, cost dashboards, and an audit MCP server for browsing past sessions.

## 6. MVP Scope (Delivered Version)

### 6.1 What's In

| Feature | Rationale |
|---|---|
| LiteLLM custom provider (completion + streaming) | Core plumbing — must work |
| Claude Agent SDK integration | The engine — must work |
| MCP SQLite connectivity | Simplest DB for demo, zero setup |
| Data analyst system prompt with schema injection | The intelligence layer — Claude needs to know the schema |
| Read-only safety (tool allowlist + disabled Bash + read-only DB user) | Hard enforcement — must-have for any DB-touching agent |
| Structured audit logging (per-request, session-correlated) | Traceability — every insight traceable to exact queries |
| Environment variable configuration | Simplest config mechanism; works natively with Docker |

### 6.2 What's Deferred (and Why)

| Feature | Deferred because |
|---|---|
| PostgreSQL/MySQL MCP servers | SQLite proves the pattern; adding DBs is config, not architecture |
| YAML config file | Env vars are sufficient for MVP's ~5 config values. YAML adds a config loader and schema for no added value yet. |
| Docker Compose | MVP runs via `pip install`. Docker Compose is a post-MVP convenience for one-command deployment. |
| Prompt sanitization (hardened) | Heuristic-based, bypassable. Hard enforcement layers (read-only DB, disabled tools) are sufficient for internal use. Input length limit provides basic protection. |
| Health endpoint | LiteLLM has its own `/health`. Custom health check is a post-MVP nicety. |
| Capability profiles / virtual keys | LiteLLM supports natively; documenting the pattern is sufficient |
| Contextual schema injection | Full schema works for demo-sized DBs; optimization can come later |
| Conversation memory / sessions | Agent SDK supports sessions; wiring through is straightforward but time-consuming |
| Result caching, Langfuse, action transparency | LiteLLM has these built-in; enabling them is config, not code |

### 6.3 Key Design Decisions & Tradeoffs

| Decision | Tradeoff | Rationale |
|---|---|---|
| MCP for DB access (not custom connectors) | Depends on MCP ecosystem quality | Avoids reinventing; leverages Claude Code's native MCP support; future-proof |
| Agent SDK (not CLI subprocess) | Newer dependency, less battle-tested | Clean async API, typed responses, session support; fallback to CLI documented |
| SQLite for MVP demo | Not "production-realistic" | Zero setup, portable — architecture is DB-agnostic by design |
| Env vars (not YAML config) | Less structured than a config file | MVP has ~5 settings. Env vars are simpler, Docker-native, zero parsing code |
| Structured logging (not file-per-session) | Less browsable than file system artifacts | No extra infrastructure. Configurable verbosity. MCP audit browser is the full-vision solution. |
| System prompt for safety | LLM could ignore instructions | Soft guardrail only; real enforcement is read-only DB user + disabled tools (see 4.5) |
| Full schema in system prompt | Doesn't scale to 500-table DBs | Works for demo; contextual injection documented as scaling solution |

## 7. Success Criteria

### Assessment Success
- [ ] Clean, well-structured codebase demonstrating engineering design thinking
- [ ] Working demo: ask a question in English, get an insight-driven answer from real data
- [ ] Design doc showing full vision vs. delivered MVP with explicit tradeoff rationale
- [ ] Security considerations addressed honestly (not just happy-path)
- [ ] Tests covering the custom provider interface

### Product Success (if continued)
- [ ] Internal user can get data insights without writing SQL
- [ ] Any OpenAI-compatible client works without modification
- [ ] Cost per query is trackable via audit logs

## 8. Project Context

Claude-DA is the second deliverable in the VICI Claude Code 7-Day Challenge assessment. The repository also contains the SubTerminator project (MCP-based browser orchestration CLI). Claude-DA is a **separate project** within the same monorepo, with its own package directory and pyproject.toml. It shares no code with SubTerminator — they demonstrate different aspects of AI engineering.

## 9. Resolved Decisions

| Question | Decision | Rationale |
|---|---|---|
| Sample dataset domain | **E-commerce** (orders, customers, products, ~4-6 tables) | Universally understood, natural business questions |
| MCP server packaging | **Agent SDK launches as stdio subprocesses** | No separate services needed |
| Streaming granularity | **Stream the final insight only** | Simpler UX. Action transparency is post-MVP. |
| Non-data fallback | **Agent handles it** (responds briefly, notes its primary role) | No separate router needed |
| Concurrency | **Single-user / low-concurrency** | Each request spawns independent session. No shared state risk, but resource contention untested. |
| Configuration | **Environment variables only** | ~5 settings. Simplest mechanism. Docker-native. |
| Audit approach | **Structured logging** (not file-per-session) | No extra infrastructure. Configurable verbosity. |

## 10. Pre-Implementation Gate

Run an end-to-end smoke test (Agent SDK → MCP SQLite server → query execution → response) before beginning provider implementation. If this fails, fall back to CLI subprocess approach.

## 11. Research References

| Reference | What was verified |
|---|---|
| [LiteLLM CustomLLM docs](https://docs.litellm.ai/docs/providers/custom_llm_server) | CustomLLM subclass pattern, method signatures, streaming chunk format, proxy registration |
| [LiteLLM proxy config](https://docs.litellm.ai/docs/proxy/configs) | YAML config structure, env var syntax, model_list + litellm_settings |
| [Claude Agent SDK (Python)](https://platform.claude.com/docs/en/agent-sdk/python) | Package name, async iterator interface, MCP server config (`mcp_servers` not `mcp_config`), tool control, budget/turn limits |
| [Agent SDK MCP guide](https://platform.claude.com/docs/en/agent-sdk/mcp) | Stdio subprocess MCP servers, server config types, tool naming conventions (`mcp__server__tool`) |
| [cabinlab/litellm-claude-code](https://github.com/cabinlab/litellm-claude-code) | Confirms CustomLLM approach works end-to-end. "Partial streaming" = final text only (same as our choice). OAuth-heavy; we simplify with API keys. |
| [MCP database servers](https://github.com/modelcontextprotocol) | PostgreSQL, MySQL, SQLite servers exist. Community-maintained, stdio-based. |
| [LiteLLM GitHub](https://github.com/BerriAI/litellm) | 35k+ stars, used by Stripe/Netflix/OpenAI Agents SDK. Active development. |
