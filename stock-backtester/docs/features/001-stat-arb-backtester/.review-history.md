# Review History: 001-stat-arb-backtester

## Implementation Review Iteration 5 - 2026-02-07T15:00:00Z

**Implementation Review:** APPROVED (all 4 levels pass, zero issues)
  - Level 1 (Tasks): pass — all 51 tasks across 12 phases verified
  - Level 2 (Spec): pass — all 8 ACs (AC-1 through AC-7 + AC-1b) verified
  - Level 3 (Design): pass — 9-module architecture matches design exactly
  - Level 4 (PRD): pass — all 3 pillars delivered, CLI complete
**Quality Review:** APPROVED (no blockers, no warnings, no critical issues)
**Security Review:** APPROVED (no new vulnerabilities, 2 medium + 1 low pre-existing and accepted)

**Changes Made (addressing iteration 4 warnings):**
- strategy.py: AlwaysLongStrategy changed from alias to proper subclass of EqualWeightStrategy
- test_integration.py: AC-7 test aligned to spec (n_paths=200, seed=42, 2*SE tolerance)
- simulation.py: run_verification_tests AC-7 aligned (n_paths=200, seed=seed, 2*SE tolerance)
- test_nfr.py: Added TestSimulationTiming (<120s) and TestVerificationTiming (<30s) tests
- simulation.py: Added explanatory comment for hardcoded synthetic date in MC loop

**All iteration 4 warnings resolved:**
- AlwaysLongStrategy: now proper class (was alias)
- AC-7 parameters: now n_paths=200, seed=42, 2*SE (was 100, 99, 3*SE)
- NFR timing tests: now present for simulation and verification (were missing)

**Decision:** ALL THREE REVIEWERS APPROVED. Implementation complete. 88 tests pass, 93% coverage, 0 ruff errors.

---

## Implementation Review Iteration 4 - 2026-02-07T14:00:00Z

**Implementation Review:** APPROVED (blocker was false positive — engine.py already has 3-param signature)
  - Level 1 (Tasks): pass
  - Level 2 (Spec): pass
  - Level 3 (Design): pass
  - Level 4 (PRD): pass
**Quality Review:** APPROVED (3 "needs fixes" were false positives — stale view of engine.py/simulation.py)
**Security Review:** APPROVED (2 medium + 3 low, all pre-existing)

**Changes Made (addressing iteration 3 warnings):**
- report.py: SURVIVORSHIP_WARNING updated to include "(yfinance)" per PRD
- cli.py: --slippage renamed to --slippage-k per PRD, parameter references updated
- simulation.py: run_monte_carlo now uses compute_kelly() instead of inline f_star/half_kelly
- simulation.py: Ruin loop short-circuits when half_kelly <= 0 (returns 0.0 ruin rates)
- simulation.py: KellyError added to top-level import

**Remaining Warnings (non-blocking, pre-existing):**
- Spec/design docs reference stale 5-param run_backtest signature (documentation only)
- AlwaysLongStrategy is alias instead of separate class (deliberate design decision)
- AC-7 test uses n_paths=100, seed=99, 3*SE (vs spec's 200/42/2*SE) for test stability
- Missing NFR timing tests for simulation (<120s) and verification (<30s)

**Decision:** ALL THREE REVIEWERS APPROVED. Implementation complete.

---

## Implementation Review Iteration 3 - 2026-02-07T13:00:00Z

**Implementation Review:** APPROVED (0 blockers, 6 warnings)
  - Level 1 (Tasks): pass
  - Level 2 (Spec): pass
  - Level 3 (Design): pass
  - Level 4 (PRD): pass
**Quality Review:** APPROVED (0 critical, 1 important readability, 3 minor)
**Security Review:** APPROVED (0 vulnerabilities, 2 low-severity config findings)

**Previous Blocker Fixed:**
- Half-Kelly scaling: simulation.py Step 1b computes f_star/half_kelly from historical net returns, Step 4 scales path net returns by half_kelly before ruin check, Step 5 reuses precomputed values.

**Remaining Warnings (non-blocking):**
- Survivorship warning text does not mention 'yfinance' (PRD says "Data source: yfinance (survivorship-biased)")
- CLI flag uses '--slippage' instead of PRD's '--slippage-k'
- Spec/design docs reference stale 5-param run_backtest signature; code uses 3-param
- AlwaysLongStrategy is alias instead of separate class
- run_monte_carlo computes half_kelly inline instead of calling compute_kelly()
- Ruin loop could short-circuit when half_kelly <= 0 for readability

**Decision:** ALL THREE REVIEWERS APPROVED. Implementation complete.

---

## Implementation Review Iteration 2 - 2026-02-07T12:30:00Z

**Implementation Review:** NOT APPROVED (1 blocker, 3 warnings)
  - Level 1 (Tasks): pass
  - Level 2 (Spec): FAIL
  - Level 3 (Design): pass
  - Level 4 (PRD): pass
**Quality Review:** APPROVED (0 critical, 3 important, 5 minor)
**Security Review:** APPROVED (0 vulnerabilities)

**Issues:**
- [blocker] [Level 2] implementation-reviewer: Monte Carlo ruin detection does not scale returns by half-Kelly. Spec Section 3.7 requires: "Scale net returns by (half_kelly / 1.0) to simulate leveraged returns." Implementation at simulation.py:132-133 runs backtest at 1x leverage and checks ruin on unscaled equity curve. (at: simulation.py:132-145)
  Suggestion: Compute half_kelly from historical backtest before MC loop, scale each path's net returns by half_kelly before building equity curve for ruin check.
- [warning] [Level 2] implementation-reviewer: Spec/design docs reference stale 5-param run_backtest signature; code now uses 3-param. (at: spec.md, design.md)
- [warning] [Level 4] implementation-reviewer: Survivorship warning text omits 'yfinance' mentioned in PRD. (at: report.py)
- [warning] [Level 4] implementation-reviewer: CLI flag uses '--slippage' instead of PRD's '--slippage-k'. (at: cli.py)

**Changes Made:**
- Added Step 1b in run_monte_carlo: compute half_kelly from historical net returns
- Step 4: scale each path's net returns by half_kelly before building equity curve for ruin detection
- Step 5: reuse f_star/half_kelly from Step 1b instead of recomputing
- Initialized f_star=0.0 in else branch to satisfy pyright

---

## Task Chain Review v5 - 2026-02-07T00:00:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 4 warnings, 3 suggestions)

**Warnings:**
- [warning] Task 5.4 pipeline step 8: equity normalization mechanism not explicit (divide by equity_curve.iloc[warmup_end_idx]) (at: Task 5.4)
- [warning] Task 6.1: drawdown duration counting convention could be more explicit (bars 1,2,3 from peak-exclusive to recovery-inclusive) (at: Task 6.1)
- [warning] Task 8.5: BacktestConfig construction for per-path synthetic backtests not explicit (from SimulationConfig fields) (at: Task 8.5)
- [warning] Parallel Groups table: Group C grouping of Phase 9 with Phase 8 may mislead — Phase 9 depends only on types (at: Dependencies)

**Suggestions:**
- Task 2.2: Correct spec section reference from "3.6" to design Section 2.5 (pandas rolling.std() defaults to ddof=1)
- Task 10.1: Note mock data (60 bars) is sufficient for calibration (smoke test)
- Task 10.1: Add CliRunner import pattern note

**No changes needed — all warnings are minor clarification opportunities, not execution blockers.**

---

## Task Review Iteration 5 - 2026-02-07T00:00:00Z

**Reviewer:** task-reviewer (skeptic)
**Decision:** Approved (0 blockers, 0 warnings, 3 suggestions)

**Suggestions:**
- Task 10.1: Add parenthetical about mock yfinance returning capitalized columns per Task 3.1 pattern
- Dependency graph: Phase 8 depends on 6.3+7.5 but simulation.py doesn't import metrics.py — conservative but safe
- Task 6.1: Trim forward reference to report.py behavior from test_sortino_all_positive

**All 5 v4 warnings confirmed resolved. Zero warnings remaining.**

---

## Task Chain Review v4 - 2026-02-07T00:00:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 4 warnings, 3 suggestions)

**Warnings:**
- [warning] Task 5.4: run_backtest signature ambiguity — config object vs explicit slippage_k/commission_per_share params (at: Task 5.4)
- [warning] Task 8.5: run_monte_carlo dependency on metrics.py not explicitly mentioned in Phase 8 dependency note (at: Task 8.5)
- [warning] Task 10.2b: SimulationConfig → BacktestConfig mapping not specified (at: Task 10.2b)
- [warning] Task 6.1: max_drawdown sign convention — task says "positive float" but MetricsResult spec may use negative (at: Task 6.1)

**Suggestions:**
- Task 9.1: Add test for report.py handling of float('inf') Sortino display
- Task 5.4: Clarify whether run_backtest receives BacktestConfig or unpacked params
- Task 10.2b: Specify how SimulationConfig fields map to BacktestConfig for the internal run_backtest call

**Changes Made (v3 → v4):**
All 9 remaining v3 reviewer warnings addressed:
- Task 1.1: Added BacktestConfig NO Python defaults note (CLI-level Typer Option defaults only)
- Task 1.2: Changed test from "defaults match spec" to "missing fields raises TypeError"
- Task 2.2: Pre-computed trailing vol expected values (bar 2 ≈ 0.014072, bar 3 ≈ 0.011494, bar 4 ≈ 0.011475)
- Task 5.2: Refined cost_approximation_bound to absolute threshold < 0.01
- Task 6.1: Specified Sortino returns float('inf') for all-positive returns
- Task 8.2: Specified check_ruin extraction as module-level helper for testability
- Task 8.3: Specified per-path Sharpe computation method (inline, not via compute_metrics)
- Task 8.5: Added testing note documenting 3 test vectors for Monte Carlo loop
- Task 10.1: Specified simulate mock shape (>= 30 bars, 1% daily growth)
- Task 10.2b: Added design departure note (spec simplifies CLI vs design Pipeline 2)

---

## Task Review Iteration 4 - 2026-02-07T00:00:00Z

**Reviewer:** task-reviewer (skeptic)
**Decision:** Approved (0 blockers, 5 warnings, 5 suggestions)

**Warnings:**
- [warning] Task 5.4: run_backtest signature — unclear if slippage_k/commission_per_share have Python defaults or come from config (at: Task 5.4)
- [warning] Task 6.1: max_drawdown sign convention — positive in task description vs potentially negative in MetricsResult (at: Task 6.1)
- [warning] Task 8.5b: run_verification_tests tested only indirectly via integration tests (at: Task 8.5b)
- [warning] Task 2.2: trailing vol ddof=1 not explicitly stated in task description (at: Task 2.2)
- [warning] Task 9.1: missing test for report.py handling of float('inf') Sortino display (at: Task 9.1)

**Suggestions:**
- Add explicit ddof=1 note to Task 2.2 test description
- Add report.py inf-Sortino display test to Task 9.1
- Clarify Task 5.4 signature vs config pattern
- Task 8.5b: Add direct unit test for run_verification_tests
- Task 6.1: Standardize max_drawdown sign convention across spec/tasks

**Changes Made (v3 → v4):**
Same 9 edits as listed above — all addressing v3 reviewer warnings.

---

## Task Chain Review v3 - 2026-02-07T00:00:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 4 warnings, 2 suggestions)

**Warnings:**
- [warning] Task 8.5 done-when does not clarify how Monte Carlo loop is tested beyond AC/ruin_detection markers (at: Task 8.5)
- [warning] Task 5.3 AC-1b uses approximate '0.0501' but exact value is 20/399 ≈ 0.050125 (at: Task 5.3)
- [warning] Phase 8 dependency note incorrectly states simulation.py depends on data.py — it receives PriceData directly (at: Task Dependencies)
- [warning] Task 10.2b note says run_monte_carlo handles historical backtest internally, contradicting design Pipeline 2 diagram where CLI orchestrates (at: Task 10.2b)

**Suggestions:**
- Task 6.1: drawdown duration spec says "peak to recovery" which is 4 bars, not "peak to trough" (3 bars)
- Task 2.2: trailing vol alternating test could pre-compute expected values

**Changes Made (v3 → v3 final):**
- Fixed AC-1b expected value from 0.0501 to exact 20/399 ≈ 0.050125 with 1e-4 tolerance
- Fixed drawdown duration to "3 trading days (bars 1,2,3 elapsed from peak to recovery)" matching spec definition
- Corrected Phase 8 dependency note: simulation.py does NOT import data.py

---

## Task Review Iteration 3 - 2026-02-07T00:00:00Z

**Reviewer:** task-reviewer (skeptic)
**Decision:** Approved (0 blockers, 6 warnings, 5 suggestions)

**Warnings:**
- [warning] Task 6.1: drawdown duration measures peak-to-trough but spec says peak-to-recovery (at: Task 6.1)
- [warning] Task 2.2: trailing vol alternating test missing pre-computed expected values (at: Task 2.2)
- [warning] Task 8.5: ruin detection embedded in run_monte_carlo, no separate helper exposed for unit testing (at: Task 8.5)
- [warning] Task 5.3: AC-1b exact expected equity is 1.050125..., not 1.0501 (at: Task 5.3)
- [warning] Task 10.1: test_cli_simulate mock shape not specified (at: Task 10.1)
- [warning] Task 1.1: BacktestConfig defaults ambiguous — spec comments vs Python defaults (at: Task 1.1)

**Suggestions:**
- Task 6.1: specify Sortino inf behavior when all returns positive
- Task 2.2: compute_costs test should construct PriceData with known trailing vol
- Task 8.3: specify per-path Sharpe computation method (inline vs compute_metrics)
- Task 5.2: refine cost_approximation_bound definition
- Overall: Phases 6/7 could start after Phase 1 for more parallelism

**Changes Made (v3 → v3 final):**
- Fixed AC-1b to use exact fraction 20/399 ≈ 0.050125 with 1e-4 tolerance
- Fixed drawdown duration to match spec's peak-to-recovery definition
- Corrected Phase 8 dependency note

---

## Task Chain Review v2 - 2026-02-07T00:00:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 4 warnings, 3 suggestions)

**Warnings:**
- [warning] Task count discrepancy: summary says 47 but actual count is 51 (at: Summary)
- [warning] Max drawdown duration ambiguous: "2 bars" vs peak-to-trough inclusive counting (at: Task 6.1)
- [warning] simulate CLI command has no test in Task 10.1 — Task 10.2b done-when untestable (at: Task 10.1)
- [warning] Phase 8 transitive dependency on data.py (via run_monte_carlo) not noted in dependency graph (at: Task Dependencies)

**Suggestions:**
- Task 8.5b done-when could assert all 8 VerificationResults pass, not just import
- Task 11.2 should note test data construction method (synthetic, not yfinance)
- Simulate command data flow (CLI → run_monte_carlo → internal backtest) could reference design sequence diagram

**Changes Made (v2 → v3):**
- Fixed task count from 47 to 51 in Summary
- Clarified max drawdown duration: 3 bars (bar 0 peak → bar 2 trough, inclusive), recovery at bar 3
- Added test_cli_simulate to Task 10.1 for simulate command coverage
- Strengthened Task 8.5b done-when to assert all 8 VerificationResults pass
- Added Phase 8 transitive dependency note on data.py in dependency graph
- Added test data construction note to Task 11.2
- Bumped tasks to v3

---

## Task Review Iteration 2 - 2026-02-07T00:00:00Z

**Reviewer:** task-reviewer (skeptic)
**Decision:** Approved (0 blockers, 5 warnings, 4 suggestions)

**Warnings:**
- [warning] AC-1b test values in Task 5.3 differ from spec's exact values (A=[100,105,110], B=[100,95,100]) (at: Task 5.3)
- [warning] Task count discrepancy: summary says 47 but actual count appears higher (at: Summary)
- [warning] Max drawdown duration "2 bars" may be off-by-one depending on inclusive/exclusive counting (at: Task 6.1)
- [warning] Task 8.5b done-when criterion only checks import, not function behavior (at: Task 8.5b)
- [warning] simulate CLI command has no corresponding test in Task 10.1 (at: Task 10.1)

**Suggestions:**
- Add expected trailing vol numeric values in Task 2.2 test_trailing_vol_alternating
- Task 11.2 should specify how test data is constructed (fixture vs live)
- Phase 8 dependency graph should note transitive dependency on data.py
- simulate command data flow should reference design's sequence diagram

**Changes Made (v2 → v3):**
- Fixed AC-1b values to match spec exactly (done in v2 edit session)
- Fixed task count to 51
- Clarified drawdown duration to 3 bars (inclusive)
- Added test_cli_simulate to Task 10.1
- Strengthened Task 8.5b done-when
- Added transitive dependency note for Phase 8
- Added test data construction note to Task 11.2

---

## Task Chain Review - 2026-02-07T00:00:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 5 warnings, 2 suggestions)

**Warnings:**
- [warning] Phase 5 dependency graph comment contradicts formal graph (mentions data.py but graph does not include it) (at: Task Dependencies, lines 440-441)
- [warning] Task 5.4 engine steps numbered 1-11 vs design's 8-step pipeline (at: Task 5.4)
- [warning] Task 8.5 combines Monte Carlo loop + verification tests — exceeds 15 min target (at: Task 8.5)
- [warning] Phase 11 tasks 11.4/11.5/11.6 could run in parallel but listed as sequential (at: Task Dependencies)
- [warning] Task 10.2 combines 3 CLI commands + error handling — exceeds 15 min target (at: Task 10.2)

**Suggestions:**
- Add time estimates per task to flag oversized tasks
- Add References section with absolute paths to spec/design/plan

---

## Task Review Iteration 1 - 2026-02-07T00:00:00Z

**Reviewer:** task-reviewer (skeptic)
**Decision:** Approved (0 blockers, 7 warnings, 6 suggestions)

**Warnings:**
- [warning] Task 2.2: trailing vol test missing specific input/expected values
- [warning] Task 5.1: PerfectForesightStrategy missing last-bar and multi-symbol behavior spec
- [warning] Task 5.3: AC-1b missing precise expected float value
- [warning] Task 6.1: Sharpe test missing hand-computed expected value
- [warning] Task 6.1: max drawdown test missing expected values
- [warning] Task 8.5: run_verification_tests has no direct unit test
- [warning] Task 11.3: optimization guidance too vague

**Suggestions:**
- Task 1.1: Note that exceptions are NOT in types.py
- Task 1.2: TDD ordering inverted for Phase 1 (implementation before tests)
- Task 3.1: Clarify Phase 3 is not a Phase 5 dependency at code level
- Task 10.2: Document simulate command redundancy with run_monte_carlo internals
- Add README task or acknowledge deferral to buffer
- Phase 11 tasks 11.4-11.6 should be parallel

---

## Stage 2: Chain Review - 2026-02-07T00:00:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 3 warnings, 2 suggestions)

**Warnings:**
- [warning] Phase 5 engine pipeline gross_returns variable naming ambiguous — unclear which intermediate value becomes BacktestResult.gross_returns (at: Phase 5, Step 4)
- [warning] Simulate CLI command pipeline redundancy with run_monte_carlo()'s internal historical backtest not documented (at: Phase 10, simulate command)
- [warning] AC-1b provenance not explicitly noted as spec-added criterion (at: AC Test Readiness Map)

**Suggestions:**
- Phase 8 simulation.py import topology (direct vs transitive dependencies) could be clarified for task breakdown
- Risk Mitigations table references "Design Section 9" without risk IDs

---

## Stage 1: Plan Review - Iteration 1 - 2026-02-07T00:00:00Z

**Reviewer:** plan-reviewer (skeptic)
**Decision:** Needs Revision (3 blockers, 7 warnings, 2 notes)

**Blockers:**
- [blocker] yfinance `multi_level_index=True` default (>= 0.2.51) breaks column normalization in Phase 3 (at: Phase 3 Step 2)
  Suggestion: Add `multi_level_index=False` to yf.download call
- [blocker] TDD ordering violated — implementation before tests in Phases 6-10 (at: Phases 6-10)
  Suggestion: Reorder all phases to RED-GREEN-REGRESSION pattern
- [blocker] Phase 8 dependency list `(types, data, engine, kelly)` inconsistent with AC Test Readiness Map showing AC-7 requires execution, strategy, metrics (at: Phase 8 header, AC Readiness Map)
  Suggestion: Correct to `(types, execution, strategy, data, engine, metrics, kelly)`

**Warnings:**
- [warning] `__main__.py` imports `from .cli import app` but cli.py doesn't exist until Phase 10 — ImportError during Phases 1-9 (at: Phase 0 Step 3)
- [warning] Missing ruin detection unit test in Phase 8 (at: Phase 8 Step 8)
- [warning] Cost approximation edge case: first trade has no prior weights, delta_w = full position (at: Phase 5)
- [warning] No rollback strategy if a phase's tests break prior phases (at: general)
- [warning] Phase 6 metrics tests lack specific known-answer values (at: Phase 6 Step 2)
- [warning] Phase 9 report tests don't verify survivorship warning text (at: Phase 9 Step 4)
- [warning] Phase 11 missing pyright validation task (at: Phase 11)

**Changes Made:**
- Fixed Blocker 1: Added `multi_level_index=False` to Phase 3's yf.download call
- Fixed Blocker 2: Rewrote Phases 2-10 with RED-GREEN-REGRESSION TDD pattern (tests first, implement to pass, run full suite)
- Fixed Blocker 3: Corrected Phase 8 dependency list to `(types, execution, strategy, data, engine, metrics, kelly)`
- Addressed warning: Phase 0 `__main__.py` now uses deferred import stub; replaced with real import in Phase 10
- Addressed warning: Added ruin detection unit tests to Phase 8 Step 2
- Addressed warning: Added cost approximation bound test to Phase 5 Step 2
- Addressed warning: Added "Regression" step after each phase to catch breakage
- Addressed warning: Added specific known-answer values to Phase 6 tests
- Addressed warning: Added survivorship warning check to Phase 9 tests
- Addressed warning: Added pyright validation task to Phase 11
- Bumped plan to v2

---

## Handoff Review - 2026-02-07T00:00:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 3 warnings, 2 suggestions)

**Warnings:**
- [warning] Implementation sequence (Section 10) does not estimate effort per step; plan phase must reconcile with PRD's 7-day timeline
- [warning] AC test dependencies on modules are implicit; plan phase should map each AC to its required module set
- [warning] pyright type checking is in design's pyproject.toml but not mentioned in spec; plan should include pyright validation task

**Suggestions:**
- Risk mitigations in Section 9 not linked to specific implementation steps; plan should map each
- PerfectForesightStrategy location (conftest.py vs strategy.py) should be explicit in task breakdown

---

## Design Review - Iteration 1 - 2026-02-07T00:00:00Z

**Reviewer:** design-reviewer (skeptic)
**Decision:** Approved (0 blockers, 6 warnings, 4 notes)

**Warnings:**
- [warning] [assumptions] yfinance >= 0.2.51 breaking changes to column structure; normalization defensive but version sensitivity needs implementation attention
  Challenge: Has column normalization been tested against yfinance >= 0.2.51?
- [warning] [consistency] Prior Art table: exceptions listed as "Adapt" but sibling centralizes exceptions (subterminator/utils/exceptions.py); our co-location is a "Depart"
  Challenge: Verified via Grep — sibling uses centralized exceptions, not co-located
- [warning] [consistency] half_kelly data flow into run_monte_carlo lacks explicit interface; function signature is (prices, strategy, config) with no half_kelly parameter
  Challenge: How does run_monte_carlo() obtain half_kelly?
- [warning] [completeness] Slippage dimensional analysis less rigorous than commission; k * sigma * |delta_w| product is dimensionless but confirmation needed
  Challenge: Confirm the product represents a fractional cost on the same scale as log-returns
- [warning] [completeness] warmup_end_idx inclusive/exclusive semantics could be clearer
  Challenge: Is equity_curve[warmup_end_idx] the start point (inclusive)?
- [warning] [feasibility] Python 3.12 requirement vs sibling project's 3.11; CI environment compatibility
  Challenge: Is 3.12 available in CI?

**Notes:**
- Prior Art table: sibling uses mypy, not pyright (row 5)
- Single-symbol degenerate case for simulate command not explicitly noted
- EqualWeight/AlwaysLong duplication is minor code smell
- Trailing vol NaN at bar 1 (< 2 observations) behavior unspecified

**Changes Made:**
- Corrected Prior Art table: exceptions changed from "Adapt" to "Depart"
- Corrected Prior Art table: type checker changed to "Depart: pyright instead of mypy"
- Added yfinance version sensitivity note in data.py design decisions
- Added half_kelly internal computation note in simulation.py design decisions
- Added dimensional analysis confirmation for slippage formula
- Clarified warmup_end_idx as inclusive positional index with example
- Added trailing vol NaN handling for early bars (treated as 0 slippage)

---


## Stage 1: Spec-Reviewer Review - Iteration 2 - 2026-02-07T00:00:00Z

**Reviewer:** spec-reviewer (skeptic)
**Decision:** Approved (0 blockers, 7 warnings, 3 suggestions)

**Context:** Spec v3 → v4. Multi-symbol equal-weight rewrite. Two blockers from iteration 1 fixed.

**Previous Blockers Fixed:**
- Portfolio return formula corrected: simple returns for cross-sectional aggregation, log-returns for time-series (Jensen's inequality)
- AC-1b added: multi-symbol known-answer test catching aggregation bug

**Warnings:**
- [warning] [assumptions] yfinance returns capitalized column names (Open, Close); spec assumes lowercase
  Suggestion: Add df.columns.str.lower() normalization in fetch_prices
- [warning] [testability] warmup_end_idx is integer positional but equity_curve is DatetimeIndex-indexed
  Suggestion: Clarify iloc usage in BacktestResult docstring
- [warning] [clarity] Sharpe uses ddof=1 while Kelly uses ddof=0 — rationale undocumented
  Suggestion: Add rationale for each convention
- [warning] [testability] PerfectForesightStrategy interface unspecified
  Suggestion: Add test fixture specification
- [warning] [assumptions] BacktestConfig not passed to run_backtest — construction gap
  Suggestion: Add config parameter to run_backtest
- [warning] [clarity] Sharpe numerator (mean*252) differs from displayed Annualized Return (exp-1)
  Suggestion: Add clarifying note
- [warning] [assumptions] Synthetic simulation data bypasses data validation — implicit
  Suggestion: Add explicit note about schema conformance

**Changes Made:**
- Added column name normalization (df.columns.str.lower()) in data layer contract
- Clarified warmup_end_idx as positional index (iloc) in BacktestResult
- Added ddof rationale for both Sharpe (ddof=1, inferential) and Kelly (ddof=0, population)
- Added PerfectForesightStrategy specification in test fixtures
- Added config parameter to run_backtest signature
- Added Sharpe numerator vs Annualized Return clarifying note
- Added synthetic data schema conformance note in simulation

---

## Stage 2: Phase Review - Iteration 2 - 2026-02-07T00:00:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 5 warnings, 3 suggestions)

**Warnings:**
- [warning] Sortino full-count convention not explicitly named
  Suggestion: Add "(full-count convention per Sortino 2001)" parenthetical
- [warning] Sharpe numerator vs displayed Annualized Return confusion (overlap with spec-reviewer)
- [warning] PerfectForesightStrategy unspecified (overlap with spec-reviewer)
- [warning] half_kelly source in run_monte_carlo unclear
  Suggestion: Specify that half_kelly comes from historical backtest compute_kelly
- [warning] theoretical_ruin_rate source ambiguous (portfolio-level vs per-symbol calibration)
  Suggestion: Specify portfolio-level mu/sigma from historical net returns

**Changes Made:**
- Added Sortino 2001 full-count convention note
- Specified half_kelly source (historical backtest compute_kelly)
- Clarified theoretical_ruin_rate uses historical portfolio-level mu/sigma
- Added SimulationError class definition
- Specified GBM calibration ddof=1 (sample std)
- Added seed scope note (AC-6/AC-7 stochastic, others deterministic)

---

## Stage 1: Spec-Reviewer Review - Iteration 1 - 2026-02-07T00:00:00Z

**Reviewer:** spec-reviewer (skeptic)
**Decision:** Needs Revision (3 blockers, 8 warnings, 5 suggestions)

**Blockers:**
- [blocker] [assumptions] yfinance `auto_adjust=True` returns adjusted OHLC in 'Close' column, no separate 'Adj Close'. Spec assumed wrong column name.
  Suggestion: Use auto_adjust=True explicitly, remove Adj Close references.
- [blocker] [testability] ddof unspecified for Kelly estimator — pandas defaults to ddof=1 but test fixture assumes ddof=0. AC-4 would fail.
  Suggestion: Specify ddof=0 in both estimator and test.
- [blocker] [assumptions] Commission formula `commission_per_share * |delta_w| * close_price` has wrong units ($^2/share^2). Needs dimensional fix.
  Suggestion: Convert to fractional cost: commission_rate = commission_per_share / close_price.

**Warnings:**
- [warning] [traceability] Report format should enumerate exact fields for TABLE output.
- [warning] [testability] Net return formula units not clarified — slippage subtracted from log-returns needs unit consistency.
- [warning] [assumptions] Monte Carlo ruin detection scales returns but not costs — optimistic approximation.
- [warning] [clarity] SMA warmup_bars vs warmup_end_idx relationship unclear.
- [warning] [testability] AC-7 Sharpe computation method ambiguous (per-path vs ensemble).
- [warning] [scope] Module count says "seven" but lists nine.
- [warning] [assumptions] OHLCV adjustment status in data contract contradicts auto_adjust=True behavior.
- [warning] [clarity] Dependency graph shows report depending on metrics/kelly, but actual dependency is on types.py.

**Changes Made:**
- Fixed all 3 blockers: yfinance auto_adjust, ddof=0 convention, commission formula with dimensional analysis
- Fixed all 8 warnings: module count, dependency graph, report field enumeration, net return formula, MC leverage caveat, SMA warmup clarification, AC-7 method, OHLCV schema
- Addressed suggestions: NFR test file added, date range defaults, data/Kelly validation distinction, reproducibility metadata deferred
- Bumped spec to v2

---

## Stage 2: Phase Review - Iteration 1 - 2026-02-07T00:00:00Z

**Reviewer:** phase-reviewer (gatekeeper)
**Decision:** Approved (0 blockers, 4 warnings, 2 suggestions)

**Warnings:**
- [warning] AlwaysLongStrategy warmup=0 interaction with shift(1) not explicit in AC-1
- [warning] Synthetic DataFrame construction for simulation paths not specified
- [warning] Annualized return convention (log vs geometric) ambiguous
- [warning] Equity curve formula not explicit

**Changes Made:**
- Added AlwaysLongStrategy warmup note to AC-1
- Added synthetic DataFrame spec to run_monte_carlo
- Clarified annualized return as geometric: exp(mean_log * 252) - 1
- Added equity curve formula: exp(cumsum(net_returns))

---
